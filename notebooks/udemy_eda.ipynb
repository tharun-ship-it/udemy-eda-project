{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä Udemy Courses: Exploratory Data Analysis\n\n**Author:** Tharun Ponnam  \n**GitHub:** [@tharun-ship-it](https://github.com/tharun-ship-it)  \n**Email:** tharunponnam007@gmail.com  \n**Dataset:** [Kaggle - Udemy Courses](https://www.kaggle.com/andrewmvd/udemy-courses)\n\n---\n\n## Abstract\n\nThis notebook presents a comprehensive **exploratory data analysis** of Udemy's online course catalog, analyzing **3,682 courses** across four major subjects spanning 2011-2017. The analysis implements a complete data science pipeline‚Äîfrom data cleaning and feature engineering through statistical analysis and visualization‚Äîto uncover insights about pricing strategies, subscriber engagement patterns, and temporal trends in the online education market.\n\n### Key Features:\n\n- **Large-Scale Analysis:** Processing of 3,682 courses with 11.9M+ total subscribers\n- **Multi-Dimensional Exploration:** Subject distribution, pricing dynamics, temporal patterns\n- **Feature Engineering:** Engagement metrics, revenue estimation, temporal feature extraction\n- **Statistical Insights:** Correlation analysis, distribution studies, comparative analysis\n- **Publication-Ready Visualizations:** Professional figures including heatmaps, distributions, and trend analysis\n\n---\n\n### üìã Table of Contents\n\n1. [Environment Setup](#1-environment-setup)\n2. [Data Loading & Exploration](#2-data-loading--exploration)\n3. [Data Cleaning & Preprocessing](#3-data-cleaning--preprocessing)\n4. [Feature Engineering](#4-feature-engineering)\n5. [Descriptive Statistics](#5-descriptive-statistics)\n6. [Univariate Analysis](#6-univariate-analysis)\n7. [Bivariate Analysis](#7-bivariate-analysis)\n8. [Temporal Analysis](#8-temporal-analysis)\n9. [Advanced Insights](#9-advanced-insights)\n10. [Conclusions & Recommendations](#10-conclusions--recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (uncomment if running in Colab)\n",
    "# !pip install pandas numpy matplotlib seaborn -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuration\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# Random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "print(\"‚úÖ Environment setup complete!\")\n",
    "print(f\"   NumPy version: {np.__version__}\")\n",
    "print(f\"   Pandas version: {pd.__version__}\")\n",
    "print(f\"   Analysis timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure visualization style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "\n",
    "# Custom color palette for subjects\n",
    "SUBJECT_COLORS = {\n",
    "    'Web Development': '#3498db',\n",
    "    'Business Finance': '#2ecc71',\n",
    "    'Graphic Design': '#e74c3c',\n",
    "    'Musical Instruments': '#9b59b6'\n",
    "}\n",
    "\n",
    "# Color palette for paid vs free\n",
    "PAYMENT_COLORS = {\n",
    "    True: '#27ae60',\n",
    "    False: '#e74c3c'\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Visualization configuration complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading & Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Google Colab: Download dataset\n",
    "# Uncomment and run if using Colab\n",
    "\n",
    "# import os\n",
    "# !pip install kaggle -q\n",
    "# !mkdir -p ~/.kaggle\n",
    "# # Upload your kaggle.json API key first\n",
    "# !kaggle datasets download -d andrewmvd/udemy-courses --unzip\n",
    "# print(\"‚úÖ Dataset downloaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_udemy_data(filepath):\n",
    "    \"\"\"\n",
    "    Load Udemy courses dataset with initial preprocessing.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    filepath : str\n",
    "        Path to the CSV file\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Loaded DataFrame with basic info displayed\n",
    "    \"\"\"\n",
    "    print(\"üì• Loading dataset...\")\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(filepath, encoding='utf-8')\n",
    "    except UnicodeDecodeError:\n",
    "        df = pd.read_csv(filepath, encoding='latin-1')\n",
    "    \n",
    "    print(f\"‚úÖ Loaded {len(df):,} courses with {len(df.columns)} features\")\n",
    "    print(f\"   Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "# Adjust path based on your environment\n",
    "DATA_PATH = '../data/udemy_courses.csv'\n",
    "\n",
    "# Alternative paths for Colab\n",
    "# DATA_PATH = 'udemy_courses.csv'\n",
    "# DATA_PATH = '/content/udemy_courses.csv'\n",
    "\n",
    "df = load_udemy_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few records\n",
    "print(\"\\nüìã First 5 Records:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types and structure\n",
    "print(\"\\nüìä Dataset Structure:\")\n",
    "print(\"=\"*60)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column overview\n",
    "print(\"\\nüìù Available Features:\")\n",
    "print(\"=\"*60)\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    dtype = df[col].dtype\n",
    "    non_null = df[col].notna().sum()\n",
    "    print(f\"  {i:2d}. {col:<25} | Type: {str(dtype):<10} | Non-null: {non_null:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Missing Value Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_missing_values(dataframe):\n",
    "    \"\"\"\n",
    "    Generate a comprehensive missing value report.\n",
    "    \"\"\"\n",
    "    missing = dataframe.isnull().sum()\n",
    "    missing_pct = (missing / len(dataframe)) * 100\n",
    "    \n",
    "    report = pd.DataFrame({\n",
    "        'Missing Count': missing,\n",
    "        'Missing %': missing_pct,\n",
    "        'Data Type': dataframe.dtypes\n",
    "    })\n",
    "    \n",
    "    report = report[report['Missing Count'] > 0].sort_values('Missing %', ascending=False)\n",
    "    \n",
    "    return report if len(report) > 0 else \"‚úÖ No missing values detected!\"\n",
    "\n",
    "print(\"\\nüîç Missing Value Analysis:\")\n",
    "print(\"=\"*60)\n",
    "analyze_missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing values pattern\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "sns.heatmap(df.isnull().T, cbar=True, cmap='YlOrRd', yticklabels=df.columns, ax=ax)\n",
    "\n",
    "ax.set_title('Missing Value Pattern (Yellow = Missing)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Sample Index')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Missing value visualization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Duplicate Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate records\n",
    "duplicates = df.duplicated().sum()\n",
    "duplicate_ids = df['course_id'].duplicated().sum()\n",
    "\n",
    "print(\"\\nüîÑ Duplicate Analysis:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"   Complete duplicate rows: {duplicates:,}\")\n",
    "print(f\"   Duplicate course IDs: {duplicate_ids:,}\")\n",
    "\n",
    "if duplicates > 0:\n",
    "    print(f\"\\n   ‚ö†Ô∏è Removing {duplicates} duplicate rows...\")\n",
    "    df = df.drop_duplicates()\n",
    "    print(f\"   ‚úÖ Dataset now has {len(df):,} unique records\")\n",
    "else:\n",
    "    print(\"   ‚úÖ No duplicates found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Data Type Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamp to datetime\n",
    "df['published_timestamp'] = pd.to_datetime(df['published_timestamp'])\n",
    "\n",
    "# Convert boolean payment status\n",
    "df['is_paid'] = df['is_paid'].astype(bool)\n",
    "\n",
    "print(\"\\nüîß Data Type Conversions:\")\n",
    "print(\"=\"*60)\n",
    "print(\"   ‚úÖ 'published_timestamp' ‚Üí datetime64\")\n",
    "print(\"   ‚úÖ 'is_paid' ‚Üí boolean\")\n",
    "print(f\"\\n   Date range: {df['published_timestamp'].min().strftime('%Y-%m-%d')} to {df['published_timestamp'].max().strftime('%Y-%m-%d')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract temporal features\n",
    "df['published_year'] = df['published_timestamp'].dt.year\n",
    "df['published_month'] = df['published_timestamp'].dt.month\n",
    "df['published_day_of_week'] = df['published_timestamp'].dt.dayofweek\n",
    "df['published_quarter'] = df['published_timestamp'].dt.quarter\n",
    "\n",
    "day_mapping = {0: 'Monday', 1: 'Tuesday', 2: 'Wednesday', 3: 'Thursday', \n",
    "               4: 'Friday', 5: 'Saturday', 6: 'Sunday'}\n",
    "df['day_name'] = df['published_day_of_week'].map(day_mapping)\n",
    "\n",
    "print(\"\\nüìÖ Temporal Features Created:\")\n",
    "print(\"=\"*60)\n",
    "print(\"   ‚úÖ published_year, published_month, published_quarter\")\n",
    "print(\"   ‚úÖ published_day_of_week, day_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create engagement metrics\n",
    "df['reviews_per_subscriber'] = np.where(df['num_subscribers'] > 0,\n",
    "    df['num_reviews'] / df['num_subscribers'], 0)\n",
    "\n",
    "df['lectures_per_hour'] = np.where(df['content_duration'] > 0,\n",
    "    df['num_lectures'] / df['content_duration'], 0)\n",
    "\n",
    "df['estimated_revenue'] = np.where(df['is_paid'],\n",
    "    df['price'] * df['num_subscribers'], 0)\n",
    "\n",
    "df['engagement_score'] = df['reviews_per_subscriber'] * 100\n",
    "\n",
    "print(\"\\nüìä Engagement Metrics Created:\")\n",
    "print(\"=\"*60)\n",
    "print(\"   ‚úÖ reviews_per_subscriber, lectures_per_hour\")\n",
    "print(\"   ‚úÖ estimated_revenue, engagement_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical features summary\n",
    "numerical_cols = ['price', 'num_subscribers', 'num_reviews', 'num_lectures', 'content_duration']\n",
    "\n",
    "print(\"\\nüìà Numerical Features Summary:\")\n",
    "print(\"=\"*80)\n",
    "df[numerical_cols].describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features summary\n",
    "print(\"\\nüìä Categorical Features Summary:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nüéØ Subject Distribution:\")\n",
    "for subject, count in df['subject'].value_counts().items():\n",
    "    print(f\"   ‚Ä¢ {subject}: {count:,} courses ({count/len(df)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nüéöÔ∏è Level Distribution:\")\n",
    "for level, count in df['level'].value_counts().items():\n",
    "    print(f\"   ‚Ä¢ {level}: {count:,} courses ({count/len(df)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nüí∞ Payment Status:\")\n",
    "print(f\"   ‚Ä¢ Paid: {df['is_paid'].sum():,} ({df['is_paid'].mean()*100:.1f}%)\")\n",
    "print(f\"   ‚Ä¢ Free: {(~df['is_paid']).sum():,} ({(~df['is_paid']).mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of key numerical features\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "features_to_plot = ['price', 'num_subscribers', 'num_reviews', \n",
    "                    'num_lectures', 'content_duration', 'engagement_score']\n",
    "\n",
    "for idx, col in enumerate(features_to_plot):\n",
    "    ax = axes[idx]\n",
    "    data = df[col].dropna()\n",
    "    \n",
    "    if col in ['num_subscribers', 'num_reviews']:\n",
    "        data = data[data > 0]\n",
    "        ax.hist(data, bins=50, alpha=0.7, color='#3498db', edgecolor='white')\n",
    "        ax.set_xscale('log')\n",
    "    else:\n",
    "        ax.hist(data, bins=50, alpha=0.7, color='#3498db', edgecolor='white')\n",
    "    \n",
    "    ax.axvline(data.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {data.mean():,.1f}')\n",
    "    ax.axvline(data.median(), color='green', linestyle='-', linewidth=2, label=f'Median: {data.median():,.1f}')\n",
    "    \n",
    "    ax.set_title(f'Distribution of {col}', fontsize=12, fontweight='bold')\n",
    "    ax.legend(fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Numerical distribution visualization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subject distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "subject_counts = df['subject'].value_counts()\n",
    "colors = [SUBJECT_COLORS.get(s, '#95a5a6') for s in subject_counts.index]\n",
    "\n",
    "# Bar chart\n",
    "bars = axes[0].bar(subject_counts.index, subject_counts.values, color=colors, edgecolor='white', linewidth=2)\n",
    "for bar, val in zip(bars, subject_counts.values):\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 20,\n",
    "                 f'{val:,}', ha='center', fontweight='bold')\n",
    "axes[0].set_title('Course Count by Subject', fontsize=14, fontweight='bold')\n",
    "axes[0].tick_params(axis='x', rotation=15)\n",
    "\n",
    "# Pie chart\n",
    "axes[1].pie(subject_counts.values, labels=subject_counts.index, autopct='%1.1f%%',\n",
    "            colors=colors, explode=[0.02]*len(subject_counts), shadow=True)\n",
    "axes[1].set_title('Subject Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "correlation_cols = ['price', 'num_subscribers', 'num_reviews', 'num_lectures', \n",
    "                    'content_duration', 'engagement_score']\n",
    "correlation_matrix = df[correlation_cols].corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, fmt='.2f', cmap='RdBu_r',\n",
    "            center=0, square=True, linewidths=0.5, cbar_kws={'shrink': 0.8})\n",
    "\n",
    "ax.set_title('Feature Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Key Correlations:\")\n",
    "print(f\"   ‚Ä¢ Subscribers vs Reviews: {correlation_matrix.loc['num_subscribers', 'num_reviews']:.3f}\")\n",
    "print(f\"   ‚Ä¢ Price vs Subscribers: {correlation_matrix.loc['price', 'num_subscribers']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subscribers by subject\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "total_subs = df.groupby('subject')['num_subscribers'].sum().sort_values(ascending=True)\n",
    "colors = [SUBJECT_COLORS.get(s, '#95a5a6') for s in total_subs.index]\n",
    "\n",
    "bars = axes[0].barh(total_subs.index, total_subs.values, color=colors, edgecolor='white')\n",
    "for bar, val in zip(bars, total_subs.values):\n",
    "    axes[0].text(val + 50000, bar.get_y() + bar.get_height()/2, f'{val/1e6:.1f}M', va='center', fontweight='bold')\n",
    "axes[0].set_title('Total Subscribers by Subject', fontsize=14, fontweight='bold')\n",
    "\n",
    "avg_subs = df.groupby('subject')['num_subscribers'].mean().sort_values(ascending=True)\n",
    "colors = [SUBJECT_COLORS.get(s, '#95a5a6') for s in avg_subs.index]\n",
    "bars = axes[1].barh(avg_subs.index, avg_subs.values, color=colors, edgecolor='white')\n",
    "for bar, val in zip(bars, avg_subs.values):\n",
    "    axes[1].text(val + 100, bar.get_y() + bar.get_height()/2, f'{val:,.0f}', va='center', fontweight='bold')\n",
    "axes[1].set_title('Average Subscribers per Course', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price analysis\n",
    "paid_courses = df[df['is_paid'] == True].copy()\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Price by subject\n",
    "sns.boxplot(data=paid_courses, x='subject', y='price', palette='Set2', ax=axes[0,0])\n",
    "axes[0,0].set_title('Price Distribution by Subject', fontweight='bold')\n",
    "axes[0,0].tick_params(axis='x', rotation=15)\n",
    "\n",
    "# Price vs Subscribers\n",
    "axes[0,1].scatter(paid_courses['price'], paid_courses['num_subscribers'], alpha=0.5, s=30)\n",
    "axes[0,1].set_xlabel('Price (USD)')\n",
    "axes[0,1].set_ylabel('Subscribers')\n",
    "axes[0,1].set_title('Price vs Subscribers', fontweight='bold')\n",
    "axes[0,1].set_yscale('log')\n",
    "\n",
    "# Price histogram\n",
    "axes[1,0].hist(paid_courses['price'], bins=50, alpha=0.7, color='#27ae60', edgecolor='white')\n",
    "axes[1,0].axvline(paid_courses['price'].median(), color='blue', linestyle='-', linewidth=2, \n",
    "                  label=f\"Median: ${paid_courses['price'].median():.0f}\")\n",
    "axes[1,0].set_title('Price Distribution', fontweight='bold')\n",
    "axes[1,0].legend()\n",
    "\n",
    "# Price by level\n",
    "sns.violinplot(data=paid_courses, x='level', y='price', palette='viridis', ax=axes[1,1])\n",
    "axes[1,1].set_title('Price by Level', fontweight='bold')\n",
    "axes[1,1].tick_params(axis='x', rotation=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free vs Paid comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Pie chart\n",
    "payment_counts = df['is_paid'].value_counts()\n",
    "axes[0].pie(payment_counts.values, labels=['Paid', 'Free'], autopct='%1.1f%%',\n",
    "            colors=['#27ae60', '#e74c3c'], explode=[0.02, 0.02], shadow=True)\n",
    "axes[0].set_title('Paid vs Free Distribution', fontweight='bold')\n",
    "\n",
    "# Subscriber comparison\n",
    "subs_by_payment = df.groupby('is_paid')['num_subscribers'].mean()\n",
    "axes[1].bar(['Free', 'Paid'], subs_by_payment.values, color=['#e74c3c', '#27ae60'], edgecolor='white')\n",
    "axes[1].set_title('Average Subscribers', fontweight='bold')\n",
    "axes[1].set_ylabel('Average Subscribers')\n",
    "\n",
    "# Review comparison\n",
    "df['payment_type'] = df['is_paid'].map({True: 'Paid', False: 'Free'})\n",
    "sns.boxplot(data=df, x='payment_type', y='num_reviews', palette=['#e74c3c', '#27ae60'], ax=axes[2])\n",
    "axes[2].set_yscale('log')\n",
    "axes[2].set_title('Review Distribution', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Temporal Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yearly publication trend\n",
    "yearly_stats = df.groupby('published_year').agg({'course_id': 'count', 'num_subscribers': 'sum'})\n",
    "yearly_stats.columns = ['courses', 'total_subscribers']\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Line plot\n",
    "axes[0].plot(yearly_stats.index, yearly_stats['courses'], marker='o', linewidth=2, markersize=8, color='#3498db')\n",
    "axes[0].fill_between(yearly_stats.index, yearly_stats['courses'], alpha=0.3, color='#3498db')\n",
    "axes[0].set_title('Courses Published per Year', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Year')\n",
    "axes[0].set_ylabel('Number of Courses')\n",
    "\n",
    "for x, y in zip(yearly_stats.index, yearly_stats['courses']):\n",
    "    axes[0].annotate(f'{y:,}', (x, y), textcoords='offset points', xytext=(0, 10), ha='center', fontweight='bold')\n",
    "\n",
    "# Stacked area by subject\n",
    "subject_yearly = df.groupby(['published_year', 'subject']).size().unstack(fill_value=0)\n",
    "subject_yearly.plot(kind='area', stacked=True, ax=axes[1], alpha=0.7,\n",
    "                    color=[SUBJECT_COLORS.get(s, '#95a5a6') for s in subject_yearly.columns])\n",
    "axes[1].set_title('Publications by Subject Over Time', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(title='Subject', loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìÖ Yearly Growth:\")\n",
    "for year in yearly_stats.index:\n",
    "    print(f\"   {year}: {yearly_stats.loc[year, 'courses']:,} courses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly and weekly patterns\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Monthly\n",
    "monthly_counts = df.groupby('published_month').size()\n",
    "month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "axes[0].bar(range(1, 13), monthly_counts.values, color=sns.color_palette('coolwarm', 12), edgecolor='white')\n",
    "axes[0].set_xticks(range(1, 13))\n",
    "axes[0].set_xticklabels(month_names)\n",
    "axes[0].set_title('Publications by Month', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Weekly\n",
    "daily_counts = df.groupby('published_day_of_week').size()\n",
    "day_names = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "axes[1].bar(range(7), daily_counts.values, color=sns.color_palette('viridis', 7), edgecolor='white')\n",
    "axes[1].set_xticks(range(7))\n",
    "axes[1].set_xticklabels(day_names)\n",
    "axes[1].set_title('Publications by Day of Week', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Advanced Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 courses\n",
    "print(\"\\nüèÜ Top 10 Most Popular Courses:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "top_courses = df.nlargest(10, 'num_subscribers')[['course_title', 'subject', 'num_subscribers', 'price', 'is_paid']].copy()\n",
    "top_courses['num_subscribers'] = top_courses['num_subscribers'].apply(lambda x: f\"{x:,}\")\n",
    "top_courses['price'] = top_courses.apply(lambda x: f\"${x['price']:.0f}\" if x['is_paid'] else \"Free\", axis=1)\n",
    "top_courses = top_courses.drop('is_paid', axis=1)\n",
    "top_courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top courses\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "top_10 = df.nlargest(10, 'num_subscribers')\n",
    "colors = [SUBJECT_COLORS.get(s, '#95a5a6') for s in top_10['subject']]\n",
    "titles = [t[:40] + '...' if len(t) > 40 else t for t in top_10['course_title']]\n",
    "\n",
    "bars = ax.barh(range(len(top_10)), top_10['num_subscribers'].values, color=colors, edgecolor='white')\n",
    "ax.set_yticks(range(len(top_10)))\n",
    "ax.set_yticklabels(titles)\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel('Number of Subscribers')\n",
    "ax.set_title('Top 10 Most Popular Courses', fontsize=14, fontweight='bold')\n",
    "\n",
    "for i, val in enumerate(top_10['num_subscribers'].values):\n",
    "    ax.text(val + 5000, i, f'{val:,}', va='center', fontweight='bold')\n",
    "\n",
    "legend_handles = [plt.Rectangle((0,0), 1, 1, color=c) for c in SUBJECT_COLORS.values()]\n",
    "ax.legend(legend_handles, SUBJECT_COLORS.keys(), title='Subject', loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executive summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìã EXECUTIVE SUMMARY: Udemy Courses Analysis\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    "üìä Dataset Overview\n",
    "   ‚Ä¢ Total Courses: {len(df):,}\n",
    "   ‚Ä¢ Date Range: {df['published_timestamp'].min().strftime('%Y-%m-%d')} to {df['published_timestamp'].max().strftime('%Y-%m-%d')}\n",
    "   ‚Ä¢ Subjects: {df['subject'].nunique()}\n",
    "\n",
    "üë• Subscribers\n",
    "   ‚Ä¢ Total: {df['num_subscribers'].sum():,}\n",
    "   ‚Ä¢ Average per Course: {df['num_subscribers'].mean():,.0f}\n",
    "   ‚Ä¢ Top Subject: {df.groupby('subject')['num_subscribers'].sum().idxmax()}\n",
    "\n",
    "üí∞ Pricing\n",
    "   ‚Ä¢ Paid: {df['is_paid'].sum():,} ({df['is_paid'].mean()*100:.1f}%)\n",
    "   ‚Ä¢ Free: {(~df['is_paid']).sum():,} ({(~df['is_paid']).mean()*100:.1f}%)\n",
    "   ‚Ä¢ Median Price: ${paid_courses['price'].median():.2f}\n",
    "\n",
    "üîë Key Findings\n",
    "   1. Price shows weak correlation (œÅ ‚âà {correlation_matrix.loc['price', 'num_subscribers']:.2f}) with subscribers\n",
    "   2. Web Development dominates subscriber engagement\n",
    "   3. Course publication accelerated significantly post-2013\n",
    "   4. Free courses represent {(~df['is_paid']).mean()*100:.1f}% of catalog\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"‚úÖ Summary Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusions & Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Key Findings\n",
    "\n",
    "**1. Market Composition**\n",
    "- Udemy hosts a diverse catalog spanning Web Development, Business Finance, Graphic Design, and Musical Instruments\n",
    "- Web Development commands the highest subscriber engagement\n",
    "\n",
    "**2. Pricing Dynamics**\n",
    "- Course pricing shows weak correlation with subscriber acquisition (œÅ ‚âà 0.05)\n",
    "- Quality signals outweigh price sensitivity in purchase decisions\n",
    "\n",
    "**3. Free vs. Paid**\n",
    "- Free courses (~8%) demonstrate unique engagement patterns\n",
    "- May serve as effective lead generation for instructors\n",
    "\n",
    "**4. Temporal Evolution**\n",
    "- Platform growth accelerated significantly post-2013\n",
    "- Coincided with mobile expansion and funding rounds\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Strategic Recommendations\n",
    "\n",
    "**For Course Creators:**\n",
    "- Focus on Web Development and Business Finance for maximum reach\n",
    "- Optimize descriptions rather than competing on price\n",
    "\n",
    "**For Platform Operators:**\n",
    "- Invest in recommendation algorithms\n",
    "- Consider free-tier strategies for user acquisition\n",
    "\n",
    "**For Learners:**\n",
    "- Evaluate courses on review-to-subscriber ratios\n",
    "- Consider content structure over price\n",
    "\n",
    "---\n",
    "\n",
    "### üîÆ Future Work\n",
    "\n",
    "- [ ] Sentiment analysis of reviews\n",
    "- [ ] Predictive modeling for subscribers\n",
    "- [ ] NLP analysis of titles and descriptions\n",
    "- [ ] Time series forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed data\n",
    "df.to_csv('../data/udemy_courses_analyzed.csv', index=False)\n",
    "print(\"üíæ Analyzed data saved!\")\n",
    "print(f\"\\n‚úÖ Analysis completed at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö References\n",
    "\n",
    "1. **Dataset**: Udemy Courses - [Kaggle](https://www.kaggle.com/andrewmvd/udemy-courses)\n",
    "2. **Pandas**: McKinney, W. (2010). Data Structures for Statistical Computing in Python.\n",
    "3. **Seaborn**: Waskom, M. (2021). seaborn: statistical data visualization.\n",
    "4. **Matplotlib**: Hunter, J. D. (2007). Matplotlib: A 2D Graphics Environment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
